{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_PythonForAnalytics.ipynb","provenance":[],"authorship_tag":"ABX9TyNfgZVcJWr2Q7bU180T4neM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KPt7ZfpeqvMV"},"source":["# Python for Analytics\r\n","\r\n","Python is a general purpose programming language. It can be used for anything from building a webpage to running the \"brain\" for autonomous vehicles. This notebook will focus on the specific parts of Python we'll need for data analysis and predictive modeling. Some of this you saw in the initial `IntroToPython` notebook, but this more pointed notebook will hopefully help you troubleshoot some common issues.\r\n","\r\n","## Packages\r\n","\r\n","We'll start with the packages/libraries we'll be utilizing. There are several libraries we'll use during almost every python session. \r\n","\r\n","+ `pandas` allows us to work with data frames. A data frame is an array of data where columns represent variables and rows represent observations or records. You should think of data frames as single-sheet Excel spreadsheets. These are sometimes called *flat-files* and common formats for this raw data is a `*.csv` or `*.txt` file.\r\n","+ `numpy` gives us access to advanced numerical functionality. We'll use it mostly for random number generation.\r\n","+ `matplotlib` and `seaborn` are both plotting libraries -- `matplotlib` is great for simple plots, but sometimes `seaborn` is convenient if we want to do something a bit more complex.\r\n","+ `sklearn` is the most popular machine learning library on the planet. We'll never import the full `sklearn` library, but we will import parts of it. In particular, `sklearn` gives us the specific functionality necessary to build and assess various classes of model.\r\n","\r\n","### Importing Packages\r\n","\r\n","When we initialize a python session, we get a *lean* version of the software -- it initializes with only the most basic functionality. If we wish to do anything \"specialized\", we need to load additional functionality. We do this via `import` statements. You might envision a library, much like our own Wolak Library and Learning Commons, where each room corresponds to a package and contains items on shelves that make up that package. We can import individual items, entire shelves, or the whole room!\r\n","\r\n","We'll run some of our common imports below:"]},{"cell_type":"code","metadata":{"id":"L5W3md-ZqqE_"},"source":["import pandas as pd #import the entire pandas room -- aliased as pd\r\n","import numpy as np #import the entire numpy room -- aliased as np\r\n","import matplotlib.pyplot as plt #import the entire pyplot shelf in the matplotlib room -- aliased as plt \r\n","import seaborn as sns #import the entire seaborn room -- aliased as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kgLlIs12xOuu"},"source":["### Aliasing\r\n","\r\n","You'll notice when we imported functionality (entire rooms or shelves), we used an alias (`as xxyy`). This is because when we want to use functionality from a library, we'll need to reference where python can find it. That is, if we call `plt.plot()` python will look for the `plot()` item on the `pyplot` shelf in the `matplotlib` room. This is much more convenient than typing `matplotlib.pyplot.plot()`, although they are functionally equivalent.\r\n","\r\n","## Data\r\n","\r\n","Since we're interested in analytics, we need data to learn from. The data we use will come in multiple forms:\r\n","\r\n","+ Data frames (data organized into rows and columns, like an Excel spreadsheet)\r\n","+ Columns (an individual column of a data frame)\r\n","+ Series (lists of values, not organized as a column)\r\n","\r\n","Knowing the *shape* and *type* of the data we are working with will be really helpful in troubleshooting some of the errors we will encounter.\r\n","\r\n","### Reading Data\r\n","\r\n","Let's read in some data below."]},{"cell_type":"code","metadata":{"id":"bBHxnGbzxLgq"},"source":["measels = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-25/measles.csv\")\r\n","measels.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MP-gD-AB0Fgu"},"source":["The code cell above did two things:\r\n","\r\n","1. Read in the `measels` data from the provided URL\r\n","  + You can think of this as asking Python to take out a carboard box, write `measels` on the front of it, and then dump the results of `pd.read_csv()` into the box so that we can access it later.\r\n","\r\n","2. Print out the `head()` of the `measels` data\r\n","  + You can think of this as asking python to go get that box with `measels` written on the front of it, and then show you the first five rows (which is what the `head()` function asks for).\r\n","\r\n","Notice that the `measels` data is arranged as a data frame. It seems as though each row represents a particular school district during a given academic year. The columns are measured variables (related to the mmr vaccine) on those districts and years.\r\n","\r\n","### Subsetting Data\r\n","\r\n","There are three ways we can subset data frames. We can subset by column, by row, or by both column and row. You saw a bit on this when you worked through the initial introduction to python notebook. If we want to subset by row and column simultaneously, we'll need the `.loc()` or `.iloc()` methods, but typically we can get away without them.\r\n","\r\n","#### Subsetting Columns\r\n","\r\n","Let's start by just isolating the state column."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"Ld4clhXDQgF1","executionInfo":{"status":"ok","timestamp":1611086829452,"user_tz":300,"elapsed":462,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"ad248910-072d-4328-9a54-83922c4e3cbd"},"source":["measels.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>state</th>\n","      <th>year</th>\n","      <th>name</th>\n","      <th>type</th>\n","      <th>city</th>\n","      <th>county</th>\n","      <th>district</th>\n","      <th>enroll</th>\n","      <th>mmr</th>\n","      <th>overall</th>\n","      <th>xrel</th>\n","      <th>xmed</th>\n","      <th>xper</th>\n","      <th>lat</th>\n","      <th>lng</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>A J Mitchell Elementary</td>\n","      <td>Public</td>\n","      <td>Nogales</td>\n","      <td>Santa Cruz</td>\n","      <td>NaN</td>\n","      <td>51.0</td>\n","      <td>100.0</td>\n","      <td>-1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>31.347819</td>\n","      <td>-110.938031</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>Academy Del Sol</td>\n","      <td>Charter</td>\n","      <td>Tucson</td>\n","      <td>Pima</td>\n","      <td>NaN</td>\n","      <td>22.0</td>\n","      <td>100.0</td>\n","      <td>-1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>32.221922</td>\n","      <td>-110.896103</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>Academy Del Sol - Hope</td>\n","      <td>Charter</td>\n","      <td>Tucson</td>\n","      <td>Pima</td>\n","      <td>NaN</td>\n","      <td>85.0</td>\n","      <td>100.0</td>\n","      <td>-1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>32.130493</td>\n","      <td>-111.117005</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>Academy Of Mathematics And Science South</td>\n","      <td>Charter</td>\n","      <td>Phoenix</td>\n","      <td>Maricopa</td>\n","      <td>NaN</td>\n","      <td>60.0</td>\n","      <td>100.0</td>\n","      <td>-1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>33.485447</td>\n","      <td>-112.130633</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>Acclaim Academy</td>\n","      <td>Charter</td>\n","      <td>Phoenix</td>\n","      <td>Maricopa</td>\n","      <td>NaN</td>\n","      <td>43.0</td>\n","      <td>100.0</td>\n","      <td>-1.0</td>\n","      <td>NaN</td>\n","      <td>2.33</td>\n","      <td>2.33</td>\n","      <td>33.495620</td>\n","      <td>-112.224722</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index    state     year  ...  xper        lat         lng\n","0      1  Arizona  2018-19  ...   NaN  31.347819 -110.938031\n","1      2  Arizona  2018-19  ...   NaN  32.221922 -110.896103\n","2      3  Arizona  2018-19  ...   NaN  32.130493 -111.117005\n","3      4  Arizona  2018-19  ...   NaN  33.485447 -112.130633\n","4      5  Arizona  2018-19  ...  2.33  33.495620 -112.224722\n","\n","[5 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0vT1cmezsU6","executionInfo":{"status":"ok","timestamp":1611086853816,"user_tz":300,"elapsed":500,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"fdc9535a-cb1e-49f9-8739-0ec02281973c"},"source":["measels[\"state\"]"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          Arizona\n","1          Arizona\n","2          Arizona\n","3          Arizona\n","4          Arizona\n","           ...    \n","66108    Wisconsin\n","66109    Wisconsin\n","66110    Wisconsin\n","66111    Wisconsin\n","66112    Wisconsin\n","Name: state, Length: 66113, dtype: object"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtoilOwqQsYJ","executionInfo":{"status":"ok","timestamp":1611086883730,"user_tz":300,"elapsed":461,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"837decf8-c703-4b48-9968-3a1908cc0dc5"},"source":["type(measels[\"state\"])"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.series.Series"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"BivNmmrBkoEr"},"source":["Notice that this prints out as a column, actually Python is thinking of `measels[\"state\"]` as a pandas Series object. You can verify this by wrapping the code above in the `type()` function. Try it -- edit the code cell above and then run it with `Shift+Enter` to see the result.\r\n","\r\n","We can easily select multiple columns as well. We just need to pass the *list* of column names we want to call rather than just a single column name. Passing a *list* is important."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"QiwnJkHUnDDh","executionInfo":{"status":"ok","timestamp":1611086905813,"user_tz":300,"elapsed":558,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"a63c1090-8ce6-47be-93f9-6eabaeb2446a"},"source":["measels[[\"state\", \"year\", \"enroll\", \"mmr\"]].head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state</th>\n","      <th>year</th>\n","      <th>enroll</th>\n","      <th>mmr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>51.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>22.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>85.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>60.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Arizona</td>\n","      <td>2018-19</td>\n","      <td>43.0</td>\n","      <td>100.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     state     year  enroll    mmr\n","0  Arizona  2018-19    51.0  100.0\n","1  Arizona  2018-19    22.0  100.0\n","2  Arizona  2018-19    85.0  100.0\n","3  Arizona  2018-19    60.0  100.0\n","4  Arizona  2018-19    43.0  100.0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"smtc2XppnYGo"},"source":["Notice that we used double-brackets in the code above. The inner brackets define the *list* of column names we are requesting. We again use the `.head()` method to print out the first five rows of the object we've retreived.\r\n","\r\n","**Aside (*the \"dot\" notation*):** You've noticed by this point that we have used commands of the form `object.action()`, for example `measels.head()`. This convenient notation allows us to apply the action on the right of the dot to the object on the left of the dot. We can use this convention to chain commands together -- just remember that the object to the left of the dot will be transformed by the action on the right of the dot.\r\n","\r\n","Now, let's say we wanted to know whether all 50 states are contained in the `measels` data frame. We'll go through a series of attempts before getting a clean answer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GBzLFBPo2LX","executionInfo":{"status":"ok","timestamp":1611087043160,"user_tz":300,"elapsed":422,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"312aecf7-88ba-4f4c-b0ff-afc1f972b669"},"source":["#Isolate the state column\r\n","measels[\"state\"]"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          Arizona\n","1          Arizona\n","2          Arizona\n","3          Arizona\n","4          Arizona\n","           ...    \n","66108    Wisconsin\n","66109    Wisconsin\n","66110    Wisconsin\n","66111    Wisconsin\n","66112    Wisconsin\n","Name: state, Length: 66113, dtype: object"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"arxccMQm1tPk"},"source":["Hmmm, 66113 rows of data to comb through (remember Python starts counting from 0) -- no thank you! Let's look at the unique values appearing in this column. The `unique()` function takes a column of data and only returns the unique values in that column."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0sduBbj1rP9","executionInfo":{"status":"ok","timestamp":1611087197423,"user_tz":300,"elapsed":470,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"3297aae0-5dd2-4ae7-e982-5d04a86d756d"},"source":["measels[\"state\"].unique()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n","       'Florida', 'Idaho', 'Illinois', 'Iowa', 'Maine', 'Massachusetts',\n","       'Michigan', 'Minnesota', 'Missouri', 'Montana', 'New Jersey',\n","       'New York', 'North Carolina', 'North Dakota', 'Oklahoma', 'Ohio',\n","       'Oregon', 'Pennsylvania', 'Rhode Island', 'South Dakota',\n","       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n","       'Wisconsin'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"vpp6IiIU2MxH"},"source":["Notice that the format of the data being printed out was different than when we asked to just isolate the `state` column. The type of object resulting from these two requests are different, and this can cause frustrating challenges if we are not paying close attention. We can get the same object type by converting to a `Series` using `pandas` (see below). This takes some getting used to, but aside from spelling and capitalization issues, data type errors are the most common errors we'll experience in QSO370/570."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UxUQot_4FsW","executionInfo":{"status":"ok","timestamp":1611087243767,"user_tz":300,"elapsed":576,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"4e177424-bc73-4826-8323-85f0ce26443a"},"source":["pd.Series(measels[\"state\"].unique())"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0            Arizona\n","1           Arkansas\n","2         California\n","3           Colorado\n","4        Connecticut\n","5            Florida\n","6              Idaho\n","7           Illinois\n","8               Iowa\n","9              Maine\n","10     Massachusetts\n","11          Michigan\n","12         Minnesota\n","13          Missouri\n","14           Montana\n","15        New Jersey\n","16          New York\n","17    North Carolina\n","18      North Dakota\n","19          Oklahoma\n","20              Ohio\n","21            Oregon\n","22      Pennsylvania\n","23      Rhode Island\n","24      South Dakota\n","25         Tennessee\n","26             Texas\n","27              Utah\n","28           Vermont\n","29          Virginia\n","30        Washington\n","31         Wisconsin\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"jjCSdyr64Gbb"},"source":["The `index` of the series does some counting for us. Using the `index` we notice that only 32 states were included (remember python starts counting at 0). If we hadn't converted to a Series, we could still get python to count how many unique states there are in the dataset using the `len()` function. Unfortunately chaining `.len()` does not work (there are reasons why, but they require a deeper understanding of Computer Science than we need here)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99OaalKX1-a-","executionInfo":{"status":"ok","timestamp":1611087172562,"user_tz":300,"elapsed":413,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"05be01ec-abfe-485d-ed9e-30ff3b21d691"},"source":["len(measels[\"state\"].unique())"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"zS_yHFMp2dkj"},"source":["So we have our answer! Not all of the states are included -- only 32 of them. I wonder if `New Hampshire` was included."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHUKDgyG2YtU","executionInfo":{"status":"ok","timestamp":1611087277137,"user_tz":300,"elapsed":437,"user":{"displayName":"Adam Gilbert","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1KWqLKG2SAQxx8KvqzqhM94EvqxkXs2iOw7gQWQ=s64","userId":"02074648007699947871"}},"outputId":"5e916b26-bc1c-4b73-af3d-3fe51b83b568"},"source":["print(\"New Hampshire\" in measels[\"state\"].unique()) #remember, if we want to print multiple outputs, we need the print() function\r\n","print(\"Vermont\" in measels[\"state\"].unique())"],"execution_count":21,"outputs":[{"output_type":"stream","text":["False\n","True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-foo9pH12w9C"},"source":["New Hampshire isn't included in the dataset but `Vermont` is included. Let's say we only wanted to work with data from that state. We can ask python to take out a new carboard box, write `Vermont` on the front of it, and then dump in only those rows of the `measels` data frame corresponding to `Vermont`. After doing that, we'll show the first eight rows of data from that box -- just making sure that we get what's expected. Notice the use of the \"double-equals\" sign here (`==`) which denotes a *test for equality* rather than an assignment declaring that two values are equal."]},{"cell_type":"code","metadata":{"id":"7QkUt0KV2va7"},"source":["Vermont = measels[measels[\"state\"] == \"Vermont\"]\r\n","Vermont.head(8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZjRTpt-3oO7"},"source":["Looks good to me! You'll notice that the index (those bold numbers on the side) is messed up now -- actually, the index values were inherited from the original `measels` data frame. We want to begin back at row 0, not at 59452 -- inevitably we'll run into challenges with mismatched indices in our course. We can reset the index to start counting at row 0 by using the `.reset_index()` method. Passing the argument `drop = True`, prevents the original index from being appended to the data frame as a new column. Additionally, the `inplace = True` argument saves the change to the data frame rather than making a temporary change and then immediately forgetting it."]},{"cell_type":"code","metadata":{"id":"N5PJ5wkG3ipa"},"source":["Vermont.reset_index(inplace = True, drop = True)\r\n","Vermont.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHGhfaEt5_nr"},"source":["Maybe we didn't just want to focus on Vermont -- let's build out a dataset corresponding to all of the New England States instead."]},{"cell_type":"code","metadata":{"id":"t1kNyjI650pv"},"source":["NewEngland = measels[(measels[\"state\"].isin([\"Maine\", \"New Hampshire\", \"Vermont\", \"Massachussetts\", \"Rhode Island\", \"Connecticut\"]))]\r\n","#Note: My first attempt at creating the NewEngland dataframe was wrong -- I got \r\n","#an ambiguity error and had to Google to fix it -- don't be afraid if you need \r\n","#to Google your coding errors, or post to Slack for help!\r\n","\r\n","print(NewEngland.head())\r\n","print(NewEngland[\"state\"].unique()) #still no New Hampshire"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZGytwCBr898B"},"source":["Notice that I spelled `Massachusetts` wrong. Because of this error, it doesn't show up as one of the states in the `NewEngland` dataset. Fix my mistake and re-run the code cell above.\r\n","\r\n","We've got a lot of columns here -- some, like `index` are columns that provide no information. Let's say we care about the `state`, `year`, `enroll`, and `mmr` variables. We'll create a smaller data frame by dropping those unnecessary columns below. The default for the `.drop()` method is to drop rows -- since we want to drop columns we change the axis that we are dropping along (`axis = 1`). Again we use the `inplace = True` argument to make the change permanent."]},{"cell_type":"code","metadata":{"id":"er6UHUD_6bSI"},"source":["NewEngland.drop([\"index\", \"name\", \"type\", \"city\", \"district\", \"overall\", \"xrel\", \"xmed\", \"xper\", \"lat\", \"lng\"], axis = 1, inplace = True)\r\n","NewEngland.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZi9_AC_t7E9"},"source":["Notice that if you run the previous code cell a second time you'll get an error. This is because those columns we wanted to drop are no longer part of the `NewEngland` data frame. Sometimes this can cause confusion, so it can be advantageous to remove the `inplace = True` argument and just store the result in a brand new data frame. That is, you might run: \r\n"," \r\n","  `NewEnglandSmall = NewEngland.drop([\"index\", \"name\", \"type\", \"city\", \"district\", \"overall\", \"xrel\", \"xmed\", \"xper\", \"lat\", \"lng\"], axis = 1)` \r\n","\r\n","instead of what we ran previously.\r\n","\r\n","## Computing on Data Frames and Objects\r\n","\r\n","Let's say we wanted to compute the average value for the `mmr` column of the dataset. We can do this with the `.mean()` or `.median()` methods. Remember that, in the presence of outliers the median is a preferred measure of center."]},{"cell_type":"code","metadata":{"id":"RczFSP27tOjQ"},"source":["NewEngland[\"mmr\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C83c1ZmyvssE"},"source":["Try changing the code above to compute the median rather than the mean. What do you notice? Do you think there are outliers in our dataset? Additionally, we should notice that the quantities we are computing are not the average percentage of school-aged children who have gotten the MMR vaccine -- this is the average district-wide percentage -- that is, a district with 100 students is weighted just as heavily in this computation as a district with 15,000 students. We should always take care to understand the quantities we are computing.\r\n","\r\n","Notice that if we try to apply methods designed to summarise numerical data to non-numeric columns, we'll get a type error."]},{"cell_type":"code","metadata":{"id":"wEKFlHi0vaMy"},"source":["NewEngland[\"county\"].mean()\r\n","#NewEngland[\"county\"].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dfILmuoVwwyx"},"source":["The `.mean()` method cannot be applied to strings. Now, comment out the line asking for the mean and uncomment the line asking for value counts (a frequency table). Re-run the code cell to see and appropriate summary of this column.\r\n","\r\n","Notice that the `.value_counts()` method can be applied to a pandas Series object (a column of a data frame) but not to a numpy array. Recall earlier that we looked at the results of `measels[\"state\"]` and `measels[\"state\"].unique()`; we observed that the printouts were different and saw that the object types were in fact different. Notice in the next code block, running `NewEngland[\"county\"].unique.value_counts()` throws an error. Try running `pd.Series(NewEngland[\"county\"].unique()).value_counts()` instead -- just be super careful with parentheses (and the result is quite boring)."]},{"cell_type":"code","metadata":{"id":"FNMzrkYawhdH"},"source":["NewEngland[\"county\"].unique().value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44QAG7Any1i9"},"source":["### Computing Grouped Quantities\r\n","\r\n","What follows is somewhat more advanced, but tends to be quite useful. What if we wanted to compute a quantity (say a median) for multiple groups of data -- say one for each year? We could save out individual datasets for each year and then work with those, but this is really inefficient and inconvenient. The `.groupby()` method becomes quite useful here.\r\n","\r\n","In the code cell below, we select only the five columns we are interested in. We group by `state`, `county`, and `year`, so that when we summarize (via the `.agg()` method) we'll get just a single row for each county per year. Notice that grouping by `state` is necessary since both Vermont and Massachusetts have an Essex County -- if we didn't group by `state`, Essex County, MA and Essex County, VT would fall in the same group. "]},{"cell_type":"code","metadata":{"id":"CRzd6yamygzs"},"source":["NewEngland[[\"state\", \"county\", \"year\", \"mmr\", \"enroll\"]].groupby([\"state\", \"county\", \"year\"], as_index = False).agg(\"median\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7f2SRq2KmsG"},"source":["Hey -- New Hampshire is listed as a county in Vermont. Looks like we found an issue with our dataset!\r\n","\r\n","## Summary\r\n","\r\n","Okay -- that's enough for now. Here you got a bit more familiar with the types of objects we'll be dealing with most often in QSO370 -- data frames and columns. You saw that python is picky and that it is important to be aware of the *types* of data we are working with. We purposely ran into some issues -- first we encountered simple mis-spellings and next we encountered *type errors*, where a function could not be applied to our object in its current state. We explored the \"dot notation\" a bit which allows for the object to the left of the dot to be transformed by the operation on the right of the dot. We also saw an example where the dot notation isn't allowed, but we didn't go into why that is -- it's beyond the scope of our course. \r\n","\r\n","Hopefully you feel a little bit more comfortable with using python to interact with data after moving through this notebook. You shouldn't feel like an \"expert\" yet, and you won't feel like one even after completing this course. \r\n","\r\n","## Try on your own\r\n","\r\n","Let's test your command of the material in notebooks 3 and 4 by trying a few short tasks on the `measels` data.\r\n","\r\n","1. Use `.shape` to determine the number of observations and variables contained in the `measels` data frame.\r\n","2. We saw that New Hampshire was \"incorrectly\" listed as a county in the state of Vermont. Create a `NewHampshire` data frame which consists of only the rows in the `measels` data frame where the `county` is `New Hampshire`. How many observations are there? Do you have any guesses about what might be the case here?\r\n","3. Create a new data frame called `lowVaxxRate` which contains only the counties (for each year), where the MMR vaccination rate is below 20% (`mmr` is less than 20). You'll also want to restrict that the `mmr` column should not contain the value -1.0 since that seems to indicate no recorded data. How many such districts are there?\r\n","4. $\\star$Challenge$\\star$ Create a data set called `largeDistricts` which consists of only those districts whose enrollment is in the top 1% of enrollments in the dataset. Sort the data frame by the values in the `mmr` column in ascending order. Which of these districts has the lowest overall MMR vaccination rate?"]}]}